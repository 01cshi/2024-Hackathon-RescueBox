# generated by datamodel-codegen:
#   filename:  openapi.yaml
#   timestamp: 2024-10-12T07:15:16+00:00

from __future__ import annotations

from enum import Enum
from typing import Any, Dict, List, Optional, Union

from pydantic import BaseModel, Field
from typing_extensions import Annotated


class BaseResponseModel(BaseModel):
    pass


class BatchAudioResult(BaseModel):
    results: Annotated[
        List[AudioResult], Field(description='List of audio results', min_length=1)
    ]


class BatchImageResult(BaseModel):
    results: Annotated[
        List[ImageResult], Field(description='List of image results', min_length=1)
    ]


class BatchTextResult(BaseModel):
    results: Annotated[
        List[TextResult], Field(description='List of text results', min_length=1)
    ]


class BatchVideoResult(BaseModel):
    results: Annotated[
        List[VideoResult], Field(description='List of video results', min_length=1)
    ]


class DataTypes(Enum):
    TEXT = 'TEXT'
    IMAGE = 'IMAGE'
    VIDEO = 'VIDEO'
    AUDIO = 'AUDIO'
    CUSTOM = 'CUSTOM'


class ErrorResponseModel(BaseResponseModel):
    status: Annotated[
        str,
        Field(description="The status of the operation, e.g., 'ERROR'", min_length=1),
    ]
    errors: Annotated[
        List[Union[str, Dict[str, Any]]],
        Field(description='Details about the error that occurred'),
    ]


class MLInput(BaseModel):
    pass


class MLResult(BaseModel):
    id: Annotated[str, Field(description='The ID of the result', min_length=1)]


class RequestModelGenerated(BaseModel):
    inputs: Annotated[
        List[Union[TextInput, FileInput, CustomInput]],
        Field(description='List of input items to be processed', min_length=1),
    ]
    data_type: DataTypes
    parameters: Annotated[
        Optional[Dict[str, Any]],
        Field(description='Additional parameters for the ML model'),
    ] = {}


class ResponseModel(BaseResponseModel):
    status: Annotated[
        Optional[str],
        Field(description="The status of the operation, e.g., 'SUCCESS'", min_length=1),
    ] = 'SUCCESS'
    results: Union[
        BatchTextResult, BatchImageResult, BatchVideoResult, BatchAudioResult
    ]


class TextInput(MLInput):
    text: Annotated[str, Field(description='Text to be processed', min_length=1)]


class TextResult(MLResult):
    result: Annotated[str, Field(description='The result text.', min_length=1)]


class CustomInput(MLInput):
    input: Annotated[
        Union[str, float, bool, List, Dict[str, Any]],
        Field(description='Custom input data'),
    ]


class FileInput(MLInput):
    file_path: Annotated[
        str, Field(description='Path of the file to be processed', min_length=1)
    ]


class FileResult(MLResult):
    result: Annotated[str, Field(description='Path of the result file.', min_length=1)]


class ImageResult(FileResult):
    pass


class VideoResult(FileResult):
    pass


class AudioResult(FileResult):
    pass
